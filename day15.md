# 📘 Day 15  

## ✅ Topic Covered
**Unsupervised Learning** 

## 🧠 Summary
Today’s session focused on **Unsupervised Learning**, a type of machine learning where the model works with **unlabeled data**. The model tries to **identify patterns, relationships, and structures** in the data without predefined outputs.  

### Key Steps in Unsupervised Learning:
1. **Data Collection:** Gather unlabeled data.  
2. **Data Preprocessing:** Clean, normalize, and scale data as needed.  
3. **Model Selection:** Choose suitable algorithms (clustering, dimensionality reduction, etc.).  
4. **Training:** Fit the model to data to identify patterns.  
5. **Evaluation:** Assess patterns, clusters, or reduced dimensions.  
6. **Application:** Use discovered structures for decision-making or insights.  

---

## 🧪 Common Unsupervised Learning Algorithms

| Algorithm                  | Type               | Description                                             | Example Use Case                          |
|----------------------------|------------------|---------------------------------------------------------|------------------------------------------|
| K-Means Clustering         | Clustering       | Groups data points into K clusters                      | Customer segmentation, Market analysis   |
| Hierarchical Clustering    | Clustering       | Builds tree-like hierarchy of clusters                 | Gene expression analysis, Social networks |

---

## 🔍 New Concepts Learned
- Unsupervised Learning works with **unlabeled datasets**, unlike supervised learning.  
- **Clustering** helps group similar data points based on similarity metrics.  
- **Dimensionality reduction** simplifies high-dimensional data while retaining key information.  
- Evaluation often relies on **visualization or metrics like silhouette score** rather than direct accuracy.  

---

## 💻 Activity
- Discussed real-life applications of clustering and dimensionality reduction.  
- Differentiated between **supervised vs unsupervised learning** problems.  
- Explored K-Means, hierarchical clustering, and PCA conceptually.  
- Analyzed how unsupervised learning can reveal hidden patterns in data.  

---

## 🤔 Challenges Faced
Understanding **how to evaluate clusters without labels** and interpreting dimensionality reduction outputs required careful visualization and explanation.  

---

## 🎯 Key Takeaway
Unsupervised Learning is **ideal for exploring unknown patterns**, segmenting data, and reducing complexity in high-dimensional datasets when labels are not available.  

---

## 📈 Understanding Today: 9/10  

---

### Example Scenarios
```text
# Customer Segmentation (K-Means Clustering)
Input: Customer purchase history, age, income
Output: Group customers into segments based on similarity

# Dimensionality Reduction (PCA)
Input: Dataset with 100+ features
Output: Reduced features (principal components) capturing most variance

# Anomaly Detection (Autoencoders)
Input: Network traffic data
Output: Detect unusual patterns or outliers

